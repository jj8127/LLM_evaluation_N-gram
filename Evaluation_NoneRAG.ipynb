{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/421 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1005338/3695103857.py:113: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chat_ollama_model([message])\n",
      "Evaluating: 100%|██████████| 421/421 [1:26:47<00:00, 12.37s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 완료! 결과는 'E5_PEFT_NoneRAG_new.csv'에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 421/421 [33:38<00:00,  4.80s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 완료! 결과는 'E10_PEFT_NoneRAG_new.csv'에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 421/421 [33:39<00:00,  4.80s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 완료! 결과는 'E15_PEFT_NoneRAG_new.csv'에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# main_evaluation.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLTK BLEU, METEOR 관련\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# ROUGE 관련\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Ollama 모델 로드 (사용자 정의)\n",
    "# ollama_model_load.py 파일에서 임포트하는 객체\n",
    "from ollama_model_load import DUChatbot5ep\n",
    "from ollama_model_load import DUChatbot10ep\n",
    "from ollama_model_load import DUChatbot15ep\n",
    "\n",
    "# LangChain 메시지 구조\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "# 중간/최종 결과를 저장할 때 사용할 컬럼 헤더\n",
    "columns = [\n",
    "    \"instruction\",\n",
    "    \"reference\",\n",
    "    \"generated\",\n",
    "    \"bleu_score\",\n",
    "    \"meteor_score\",\n",
    "    \"rouge_1\",\n",
    "    \"rouge_2\",\n",
    "    \"rouge_L\"\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_bleu(reference: str, generated: str) -> float:\n",
    "    \"\"\"\n",
    "    BLEU 점수를 계산한다.\n",
    "    reference와 generated를 공백 기준으로 나눈 뒤\n",
    "    NLTK sentence_bleu 함수를 사용한다.\n",
    "    smoothing_function은 문장 길이에 따른 점수 편차를 줄이기 위해 사용.\n",
    "    \"\"\"\n",
    "    reference_tokens = reference.split()\n",
    "    generated_tokens = generated.split()\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    bleu = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothing)\n",
    "    return bleu\n",
    "\n",
    "\n",
    "def calculate_meteor(reference: str, generated: str) -> float:\n",
    "    \"\"\"\n",
    "    METEOR 점수를 계산한다.\n",
    "    meteor_score 함수는 토큰 단위 리스트를 입력으로 받으므로\n",
    "    문자열을 공백 기준으로 분할한 뒤 리스트로 전달한다.\n",
    "    \"\"\"\n",
    "    reference_tokens = reference.split()\n",
    "    generated_tokens = generated.split()\n",
    "    meteor = meteor_score([reference_tokens], generated_tokens)\n",
    "    return meteor\n",
    "\n",
    "\n",
    "def calculate_rouge(reference: str, generated: str) -> dict:\n",
    "    \"\"\"\n",
    "    ROUGE-1, ROUGE-2, ROUGE-L 세 가지 점수를 계산한다.\n",
    "    use_stemmer=True 설정 시 내부적으로 어간 추출을 적용해\n",
    "    보다 일반화된 평가를 수행한다.\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "\n",
    "    return {\n",
    "        \"rouge_1\": scores[\"rouge1\"].fmeasure,\n",
    "        \"rouge_2\": scores[\"rouge2\"].fmeasure,\n",
    "        \"rouge_L\": scores[\"rougeL\"].fmeasure\n",
    "    }\n",
    "\n",
    "\n",
    "def get_chat_ollama(model_name: str):\n",
    "    \"\"\"\n",
    "    model_name에 따라 ollama_model_load.py에서 임포트해 온\n",
    "    Ollama 모델 객체를 반환한다.\n",
    "    \"\"\"\n",
    "    if model_name == \"DUCChatbot5ep\":\n",
    "        return DUChatbot5ep\n",
    "    elif model_name == \"DUChatbot10ep\":\n",
    "        return DUChatbot10ep\n",
    "    elif model_name == \"DUChatbot15ep\":\n",
    "        return DUChatbot15ep\n",
    "    else:\n",
    "        raise ValueError(f\"알 수 없는 모델 이름입니다: {model_name}\")\n",
    "\n",
    "\n",
    "def query_llm(chat_ollama_model, prompt_text: str) -> str:\n",
    "    \"\"\"\n",
    "    LangChain의 ChatPromptTemplate과 HumanMessage를 활용해\n",
    "    Ollama 모델에 프롬프트를 전달하고 답변을 받아온다.\n",
    "    \"\"\"\n",
    "    # 템플릿: 사용자 요청(user_input)에 대해 간략한 답변을 작성.\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    다음은 사용자 요청입니다:\n",
    "    {user_input}\n",
    "\n",
    "    이에 대한 답변을 간략히 작성해 주세요:\n",
    "    \"\"\"\n",
    "    template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    formatted_prompt = template.format(user_input=prompt_text)\n",
    "    message = HumanMessage(content=formatted_prompt)\n",
    "\n",
    "    # Ollama 모델 객체에 메시지 리스트를 전달하고, 응답 텍스트를 받아온다.\n",
    "    response = chat_ollama_model([message])\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    csv_file: str,\n",
    "    model_name: str,\n",
    "    output_file: str,\n",
    "    batch_size: int = 5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    1. csv_file에서 instruction과 reference 텍스트를 각각 읽어온다.\n",
    "    2. instruction을 Ollama 모델에 전달하여 답변(generated)을 생성한다.\n",
    "    3. BLEU, METEOR, ROUGE 점수를 계산한다.\n",
    "    4. batch_size마다, 중간 결과를 output_file에 CSV로 저장한다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 이미 처리한 행 수를 체크해 중간에서부터 이어서 처리하기 위함.\n",
    "    processed_count = 0\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pd.read_csv(output_file, encoding='utf-8-sig')\n",
    "        processed_count = len(existing_df)\n",
    "\n",
    "    # CSV 파일 로드 (인코딩 문제 대비 euc-kr로 재시도)\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(csv_file, encoding='euc-kr')\n",
    "\n",
    "    total_rows = len(df)\n",
    "    if processed_count >= total_rows:\n",
    "        print(\"이미 모든 데이터가 처리되었습니다.\")\n",
    "        return\n",
    "\n",
    "    # Ollama 모델 로드\n",
    "    chat_ollama_model = get_chat_ollama(model_name)\n",
    "\n",
    "    evaluation_results = []\n",
    "\n",
    "    for idx in tqdm(range(processed_count, total_rows), desc=\"Evaluating\"):\n",
    "        # CSV의 0번째 컬럼: instruction, 1번째 컬럼: reference\n",
    "        instruction = df.iloc[idx, 0]\n",
    "        reference = df.iloc[idx, 1]\n",
    "\n",
    "        # Ollama 모델로 텍스트 생성\n",
    "        generated_text = query_llm(chat_ollama_model, instruction)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        bleu_score = calculate_bleu(reference, generated_text)\n",
    "        meteor_score_value = calculate_meteor(reference, generated_text)\n",
    "        rouge_scores = calculate_rouge(reference, generated_text)\n",
    "\n",
    "        # 결과 딕셔너리 형태로 저장\n",
    "        evaluation_results.append({\n",
    "            \"instruction\": instruction,\n",
    "            \"reference\": reference,\n",
    "            \"generated\": generated_text,\n",
    "            \"bleu_score\": bleu_score,\n",
    "            \"meteor_score\": meteor_score_value,\n",
    "            \"rouge_1\": rouge_scores[\"rouge_1\"],\n",
    "            \"rouge_2\": rouge_scores[\"rouge_2\"],\n",
    "            \"rouge_L\": rouge_scores[\"rouge_L\"]\n",
    "        })\n",
    "\n",
    "        # batch_size마다 중간 결과를 output_file에 append 모드로 저장\n",
    "        if (len(evaluation_results) % batch_size == 0) or (idx == total_rows - 1):\n",
    "            partial_df = pd.DataFrame(evaluation_results, columns=columns)\n",
    "\n",
    "            # 이미 처리된 결과가 있으면 헤더 없이 이어붙이고\n",
    "            # 처음이면 헤더 포함해서 작성\n",
    "            if os.path.exists(output_file) and processed_count > 0:\n",
    "                partial_df.to_csv(output_file, mode='a', index=False, header=False, encoding='utf-8-sig')\n",
    "            else:\n",
    "                partial_df.to_csv(output_file, mode='w', index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "            evaluation_results = []\n",
    "            processed_count = idx + 1\n",
    "\n",
    "    print(f\"평가 완료! 결과는 '{output_file}'에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 5ep 모델\n",
    "    evaluate_model(\n",
    "        csv_file=\"QADataset_new.csv\",\n",
    "        model_name=\"DUCChatbot5ep\",\n",
    "        output_file=\"E5_PEFT_NoneRAG_new.csv\",\n",
    "        batch_size=5\n",
    "    )\n",
    "\n",
    "    # 2) 10ep 모델\n",
    "    evaluate_model(\n",
    "        csv_file=\"QADataset_new.csv\",\n",
    "        model_name=\"DUChatbot10ep\",\n",
    "        output_file=\"E10_PEFT_NoneRAG_new.csv\",\n",
    "        batch_size=5\n",
    "    )\n",
    "\n",
    "    # 3) 15ep 모델\n",
    "    evaluate_model(\n",
    "        csv_file=\"QADataset_new.csv\",\n",
    "        model_name=\"DUChatbot15ep\",\n",
    "        output_file=\"E15_PEFT_NoneRAG_new.csv\",\n",
    "        batch_size=5\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
